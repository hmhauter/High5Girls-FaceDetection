{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the dataset\n",
    "This script sets up the dataset to train the Network that can recognize faces\n",
    "1. Set up the database face by face\n",
    "2. The first person has to get infront of the laptop camera \n",
    "3. Start the script \n",
    "4. Give that person an unique ID when asked in the Terminal (start with 0, 1, 2, 3...)\n",
    "5. Look into the camera and try to capture different poses\n",
    "6. The images are stored in the \"dataset\" folder\n",
    "\n",
    "Remember to select the correct python environment when running the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python library for computer vision\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Initializing face capture. Look the camera and wait ...\n",
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n"
     ]
    }
   ],
   "source": [
    "# again we are starting the laptop camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video width\n",
    "cam.set(4, 480) # set video height\n",
    "\n",
    "# this is the face detection we were using before\n",
    "face_detector = cv2.CascadeClassifier('../haarcascade_frontalface_default.xml')\n",
    "\n",
    "# for each person, enter a unique id (start with 0, 1, 2, 3 ...)\n",
    "face_id = input('\\n enter user id end press <return> ==>  ')\n",
    "\n",
    "print(\"\\n [INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "\n",
    "# initalize face image counter\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    # get image from laptop camera\n",
    "    ret, img = cam.read()\n",
    "    # convert that image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # run the face detection (like in the previous exercise)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "    # if a face was detected get the face from the image\n",
    "    for (x,y,w,h) in faces:\n",
    "\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "\n",
    "        # save the image snippet in the dataset folder\n",
    "        cv2.imwrite(\"./dataset/User_\" + str(face_id) + '_' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "    \n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 30: # Take 30 face sample and stop video\n",
    "         break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise A**: Before creating the dataset think about what could improve the quality of your data. <br>\n",
    "**Exercise B**: Look through the images stored in the *dataset* subfolder. Did the dataset creation work?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
